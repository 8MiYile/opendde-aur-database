package() {
        cd "$srcdir/spark-${pkgver}-bin-hadoop3"

        install -d "${pkgdir}/usr/bin" "${pkgdir}/opt" "${pkgdir}/var/log/apache-spark" "${pkgdir}/var/lib/apache-spark/work"
        chmod 2775 "${pkgdir}/var/log/apache-spark" "${pkgdir}/var/lib/apache-spark/work"

        cp -r "${srcdir}/spark-${pkgver}-bin-hadoop3" "${pkgdir}/opt/apache-spark/"

        cd "${pkgdir}/usr/bin"
        for binary in beeline pyspark sparkR spark-class spark-shell find-spark-home spark-sql spark-submit load-spark-env.sh; do
                local binpath="/opt/apache-spark/bin/${binary}"
                ln -s "${binpath}" ${binary}
                sed -i 's|^export SPARK_HOME=.*$|export SPARK_HOME=/opt/apache-spark|' "${pkgdir}/${binpath}"
                sed -i -Ee 's/\$\(dirname "\$0"\)/$(dirname "$(readlink -f "$0")")/g' "${pkgdir}/${binpath}"
        done

        mkdir -p ${pkgdir}/etc/profile.d
        echo '#!/bin/sh' > ${pkgdir}/etc/profile.d/apache-spark.sh
        echo 'export SPARK_HOME=/opt/apache-spark' >> ${pkgdir}/etc/profile.d/apache-spark.sh
        chmod 755 ${pkgdir}/etc/profile.d/apache-spark.sh

        install -Dm644 "${srcdir}/apache-spark-master.service" "${pkgdir}/usr/lib/systemd/system/apache-spark-master.service"
        install -Dm644 "${srcdir}/apache-spark-slave@.service" "${pkgdir}/usr/lib/systemd/system/apache-spark-slave@.service"
        install -Dm644 "${srcdir}/spark-env.sh" "${pkgdir}/etc/apache-spark/spark-env.sh"
        for script in run-master.sh run-slave.sh spark-daemon-run.sh; do
            install -Dm755 "${srcdir}/${script}" "${pkgdir}/opt/apache-spark/sbin/${script}"
        done
        install -Dm644 "${srcdir}/spark-${pkgver}-bin-hadoop3/conf"/* "${pkgdir}/etc/apache-spark"

        cd "${pkgdir}/opt/apache-spark"
        mv conf conf-templates
        ln -sf "/etc/apache-spark" conf
        ln -sf "/var/lib/apache-spark/work" .
}
