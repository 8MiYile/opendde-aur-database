package() {
        cd "$srcdir/spark"

        # install files to spark home (/opt/apache-spark)
        sparkhome="$pkgdir/opt/apache-spark"
        jarpath="assembly/target/scala-2.11/jars"
        install -d "$sparkhome"
        cp -r "$srcdir/spark"/{bin,conf,data,docs,examples,licenses,python,R,sbin,CONTRIBUTING.md,LICENSE,NOTICE,README.md} "$sparkhome"
        install -D "$srcdir/spark/$jarpath"/* -t "$sparkhome/$jarpath"
        rm -rf "$sparkhome/bin"/*.cmd

        # install files to system
        install -d "$pkgdir/usr/bin" "$pkgdir/var/log/apache-spark"
        for i in $(ls "$sparkhome/bin");do ln -sf /opt/apache-spark/bin/$i "$pkgdir/usr/bin"; done
        install -D "$srcdir"/*.service -t "$pkgdir/usr/lib/systemd/system/"
        install -D "$srcdir"/{run-master.sh,run-slave.sh,spark-daemon-run.sh} "$sparkhome/sbin/"
        install -D "$srcdir/spark/conf"/* "$srcdir/spark-env.sh" -t "$pkgdir/etc/apache-spark"
        install -D "$srcdir/apache-spark.sh" "$pkgdir/etc/profile.d/apache-spark.sh"

        # lines files in system to spark home
        cd "$sparkhome"
        mv conf conf-templates
        ln -sf "/etc/apache-spark" conf
        ln -sf "/var/lib/apache-spark/work" .
}
